{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pygtrie\n",
    "import math\n",
    "import numpy as np\n",
    "import operator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens the document vectors to split to test and train\n",
    "f = open(\"r.Doc_Vec\", \"r\")\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "#Opens seperate test and train files to split the DV file.\n",
    "fTest = open(\"r.test\", \"w+\")\n",
    "fTrain = open(\"r.train\", \"w+\")\n",
    "\n",
    "#if the value of the counter is odd the data belongs to train class\n",
    "#if the value of the counter is even the data belongs to test class\n",
    "dummyCounter =0\n",
    "for line in lines:\n",
    "    dummyCounter = dummyCounter+1           #a dummyCounter to track the document ID\n",
    "    if dummyCounter%2 ==1:                  #if document ID is a odd number I say that it belongs to train set \n",
    "        fTrain.write(line)                  #saves the line into the train document\n",
    "    else:                                   #if document ID is an even number I sat that it belongs to test set\n",
    "        fTest.write(line)                   #saves the line into the test document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opens the file to start the training process\n",
    "f = open(\"r.train\", \"r\")\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "dummyDict=dict()\n",
    "dummyCounter=0\n",
    "\n",
    "#saves each line of the training data to the dictionary and array dataset\n",
    "#to make sure more pretentble for me\n",
    "for line in lines:\n",
    "    line= re.sub( '\\n', '', line)         #trims the \"\\n\" from the line\n",
    "    instances=line.split(\"\\t\")            #splits the data according to the tabs \n",
    "    dummyCounter=dummyCounter+1           #a dummy counter to save the document IDs data, it might be useful...\n",
    "    dummyList=[]                          #a dummy empty array to append the seperated data as array\n",
    "    for i in range(len(instances)):\n",
    "        dummyList.append(instances[i])    #appends each and every data into the dummy empty array/list\n",
    "    dummyDict[dummyCounter]=dummyList     #saves the dummy list to the dictionary by using document ID as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterates through the both documents to calculate the similarity between the documents\n",
    "#the results that we have found after this iteration calculates the disance by using \n",
    "#cosine similarity\n",
    "def findSimilarityBetweenDocs(doc1, doc2):    \n",
    "    j=0                                   #an empty variable to track the second documents\n",
    "    for i in range(len(doc1)):            #starts the loop by tracking the variables of first document \n",
    "        if i%2==0:                        #since we both stored the frequecy of the terms as well as the term ids there are two variables to use while calculating the cosine similarity\n",
    "            if doc1[i]<doc2[j]:           #if the term of first document is smaller than the second document\n",
    "                i=i                       #wait for loop to iterate\n",
    "            elif doc1[i]>doc2[j]:         #if the term of the first document is larger than the first document\n",
    "                j=i+2                     #iterate through the second document until find smaller than the first document\n",
    "            elif doc1[i]==doc2[j]:        #if both terms are same \n",
    "                cos_sim(doc1[i], doc2[j]) #calculate the cosine similarity between documents\n",
    "                j=i+2                     #cahnge the position of the pointer of the second document as well.\n",
    "                \n",
    "#Calculates the distance between two vectors by using cosine similarity\n",
    "def cos_sim(a, b):\n",
    "    dot_product = np.dot(a, b)                #dot product of the first and second vector\n",
    "    norm_a = np.linalg.norm(a)                #finds the length of the first vector\n",
    "    norm_b = np.linalg.norm(b)                #finds the length of the second vector\n",
    "    return dot_product / (norm_a * norm_b)    #calculates the distance\n",
    "\n",
    "#find the neighbors of the testing instances\n",
    "#gets the training set, test instances and k as a parameter to the method\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []                           #an empty array for storing the distances                                        \n",
    "    length = len(testInstance)-1             #since we have 0 the lenght should be -1\n",
    "    for x in range(len(trainingSet)):        #a loop to iterate in the traininf set\n",
    "        dist = cos_sim(testInstance, trainingSet[x]) #calculates the cosine similarity between the documents\n",
    "        distances.append((trainingSet[x], dist))     #appends the result of teh distances into the array/list\n",
    "    distances.sort(key=operator.itemgetter(1))       #sorts the distances in order to pick 5 of them\n",
    "    neighbors = []                           #an empty array to store the 5 closest neighbours\n",
    "    for x in range(k):                       #a for loop iterates to the 5 to find the closest neighbours\n",
    "        neighbors.append(distances[x][0])    #saves those distances to the empty list\n",
    "    return neighbors                         #returns the 5 neighbours\n",
    "\n",
    "#calculates the accuracy of the algorithm \n",
    "#gets the real results and predicted genres of the documents\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0                              #a dummy counter to store correct predictions\n",
    "    for x in range(len(testSet)):            #a loop to iterate in test document\n",
    "        if testSet[x][-1] is predictions[x]: #is the test set is same with the predicted result \n",
    "            correct += 1                     #increase the value of the dummy correct variable\n",
    "    return (correct/float(len(testSet))) * 100.0  #calculates the acc.\n",
    "\n",
    "similarityDict=dict()\n",
    "for i in range(len(dummyDict)):              #a loop to find the similarity between each and every document\n",
    "    dummyList=[]                             #a dummy list to store the distances\n",
    "    dummyList.append(findSimilarityBetweenDocs(dummyDict[i], dummyDict[i+1])) #finds the similarity\n",
    "    similarityDict[i] = dummyList\n",
    "\n",
    "k = 5                                         \n",
    "neighbors = getNeighbors(trainSet, testInstance, k) #finds the neighbours\n",
    "accuracy = getAccuracy(testSet, predictions)        #gets the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each and every type of document the rocchio algorithm finds centroids\n",
    "    def train(train, token_pool):\n",
    "        for term, data in trainDict.items():\n",
    "            for cl in trainDict:\n",
    "                if cl in data:\n",
    "                    centroid += data[cl]\n",
    "\n",
    "        for cl in class_labels:\n",
    "            centroids.append(np.zeros((len(self.tdict), 1)))\n",
    "            for doc in token_pool[cl]:\n",
    "                centroids[train_dict[cl]] = vec\n",
    "\n",
    "            self.centroids[self.lbl_dict[cl]] /= len(token_pool[cl])\n",
    "\n",
    "    def predict(self, doc):\n",
    "        distances = []\n",
    "        for i in range(self.k):\n",
    "            distances.append(np.linalg.norm(doc_vec - self.centroids[i]))\n",
    "        return self.class_labels[distances.index(min(distances))]\n",
    "\n",
    "    tdict = createDictionary(class_titles, pool)\n",
    "    rocchio = Rocchio(class_titles, tdict)\n",
    "    rocchio.train(pool)\n",
    "    \n",
    "    for c in rocchio.centroids:\n",
    "        print np.linalg.norm(c - rocchio.centroids[0])\n",
    "    id = 3\n",
    "    lbl = rocchio.predict(tokenizeDoc(test[class_titles[id]][3]))\n",
    "    test_lbl_pool = rocchio.predictPool(test_pool)\n",
    "    metrics = calculateMetrics(class_titles, test_lbl_pool)\n",
    "    total_F = 0\n",
    "    for cl in class_titles:\n",
    "        Acc = ((metrics[cl][\"tp\"] + metrics[cl][\"tn\"])* 1.0 / (metrics[cl][\"tp\"] + metrics[cl][\"fp\"] + metrics[cl][\"fn\"] + metrics[cl][\"tn\"]))\n",
    "        print 'accuracy = ', Acc\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
